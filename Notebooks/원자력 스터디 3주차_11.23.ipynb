{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jwLtCHGC2lnb",
    "toc-hr-collapsed": false
   },
   "source": [
    "# 모델 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPT 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [[0.99, 0, 0.01, 0, 0],\n",
    "[0.2, 0.1, 0.3, 0.2 , 0.2],\n",
    "[0.1, 0.6, 0.1, 0.1, 0.1],\n",
    "[0.5, 0.2, 0.1, 0.1, 0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[1,0,0,0,0],\n",
    "[0,0,1,0,0],\n",
    "[0,1,0,0,0],\n",
    "[0,0,0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0068584642348692"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0068584642348684"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(log(0.99) + log(0.3) + log(0.6) + log(0.1)) / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 검증셋 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV 스코어랑 LB 스코어가 어떻게 되시나요??\n",
    "- cross validation score A변화를 줬을 때, CV 올라갔따, LB 올라갔다 (이상적인) -> CV 내려갈 때, LB도 내려가는 경우 \n",
    "- leaderboard score \n",
    "- CV가 올라갈 때, LB가 내려가는, CV가 내려갈 때 LB가 올라가는 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import multiprocessing # 여러 개의 일꾼 (cpu)들에게 작업을 분산시키는 역할\n",
    "from multiprocessing import Pool \n",
    "from functools import partial # 함수가 받는 인자들 중 몇개를 고정 시켜서 새롭게 파생된 함수를 형성하는 역할\n",
    "from data_loader_v2 import data_loader_v2 # 자체적으로 만든 data loader version 2.0 ([데이콘 15회 대회] 데이터 설명 및 데이터 불러오기 영상 참조)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = '../train/'\n",
    "test_folder = '../test/'\n",
    "train_label_path = '../etc/train_label.csv'\n",
    "\n",
    "train_list = os.listdir(train_folder)\n",
    "test_list = os.listdir(test_folder)\n",
    "train_label = pd.read_csv(train_label_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 csv 파일의 상태_B로 변화는 시점이 같다라고 가정\n",
    "# 하지만, 개별 csv파일의 상태_B로 변화는 시점은 상이할 수 있음\n",
    "def data_loader_all_v2(func, files, folder='', train_label=None, event_time=10, nrows=60):   \n",
    "    func_fixed = partial(func, folder=folder, train_label=train_label, event_time=event_time, nrows=nrows)     \n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool(processes=multiprocessing.cpu_count()) \n",
    "        df_list = list(tqdm(pool.imap(func_fixed, files), total = len(files)))\n",
    "        pool.close()\n",
    "        pool.join()       \n",
    "    combined_df = pd.concat(df_list)    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 826/826 [01:47<00:00,  7.66it/s]\n"
     ]
    }
   ],
   "source": [
    "train = data_loader_all_v2(data_loader_v2, train_list, folder=train_folder, train_label=train_label, event_time=10, nrows=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [01:33<00:00,  7.69it/s]\n"
     ]
    }
   ],
   "source": [
    "test = data_loader_all_v2(data_loader_v2, test_list, folder=test_folder, train_label=None, event_time=10, nrows=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.76222538948059\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train = pd.read_csv('../train.csv', index_col = 0)\n",
    "test = pd.read_csv('../test.csv', index_col = 0)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24780, 5122), (21540, 5121))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 분리 (train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110    0.029021\n",
       "17     0.025393\n",
       "118    0.024184\n",
       "114    0.024184\n",
       "113    0.022975\n",
       "         ...   \n",
       "137    0.001209\n",
       "153    0.001209\n",
       "185    0.001209\n",
       "42     0.001209\n",
       "135    0.001209\n",
       "Name: label, Length: 198, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts() / train['label'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤하게 train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['label'], axis=1)\n",
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, X_val, y_trn, y_val = train_test_split(X_train, y_train, test_size = 0.2, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19848, 5121), (4962, 5121), (19848,), (4962,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trn.shape, X_val.shape, y_trn.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    \n",
    "    model = RandomForestClassifier(random_state=0, verbose=1, n_jobs=-1)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "model = train_model(X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "y_val_binarize = label_binarize(y_val, classes = range(198))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 67,  68,  83, ...,  28,  68, 193], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_binarize[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8721437176576072"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_val_binarize, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110    0.029021\n",
       "17     0.025393\n",
       "118    0.024184\n",
       "114    0.024184\n",
       "113    0.022975\n",
       "         ...   \n",
       "137    0.001209\n",
       "153    0.001209\n",
       "185    0.001209\n",
       "42     0.001209\n",
       "135    0.001209\n",
       "Name: label, Length: 198, dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts() / train['label'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110    570\n",
       "17     511\n",
       "118    483\n",
       "114    472\n",
       "117    471\n",
       "      ... \n",
       "146     21\n",
       "49      20\n",
       "36      20\n",
       "140     20\n",
       "44      19\n",
       "Name: label, Length: 198, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137    26\n",
       "153    25\n",
       "42     21\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trn.value_counts()[[137, 153, 42]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다행히도 198개의 라벨이 모두 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.676753414529926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3037120563564033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5624730298106417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.166969298265241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8046789752691896\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "for trn_idx, val_idx in skf.split(X_train, y_train):\n",
    "    \n",
    "    X_trn, X_val, y_trn, y_val = X_train.iloc[trn_idx], X_train.iloc[val_idx], y_train.iloc[trn_idx], y_train.iloc[val_idx]\n",
    "    trained_model = train_model(X_trn, y_trn)\n",
    "    y_pred = trained_model.predict_proba(X_val)\n",
    "    y_val_binarize = label_binarize(y_val, classes = range(198))\n",
    "    loss = log_loss(y_val_binarize, y_pred)\n",
    "    print(loss)\n",
    "    loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.676753414529926, 1.3037120563564033, 1.5624730298106417, 1.166969298265241, 1.8046789752691896]\n",
      "1.7029173548462804\n"
     ]
    }
   ],
   "source": [
    "print(loss_list)\n",
    "print(np.mean(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110    720\n",
       "17     630\n",
       "118    600\n",
       "114    600\n",
       "113    570\n",
       "      ... \n",
       "137     30\n",
       "153     30\n",
       "185     30\n",
       "42      30\n",
       "135     30\n",
       "Name: label, Length: 198, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "720 * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110    576\n",
       "17     504\n",
       "118    480\n",
       "114    480\n",
       "113    456\n",
       "      ... \n",
       "137     24\n",
       "153     24\n",
       "185     24\n",
       "42      24\n",
       "135     24\n",
       "Name: label, Length: 198, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110    144\n",
       "17     126\n",
       "118    120\n",
       "114    120\n",
       "117    114\n",
       "      ... \n",
       "45       6\n",
       "49       6\n",
       "98       6\n",
       "57       6\n",
       "195      6\n",
       "Name: label, Length: 198, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM\n",
    "\n",
    "- Boosting은 여러개의 트리(혹은 다른 모델)를 만들되, 랜덤포레스트나 배깅과 같은 기법과는 다른게 기존에 있는 예측기를 조금씩 발전시켜서 이를 합한다는 개념이다.\n",
    "\n",
    "- 랜덤포레스트는 병렬로 무지막지하게 많은 다양한 결정트리를 동시에 만든다면 부스팅은 점진적으로 Decision Tree를 발전시킨뒤에 이를 통합하는 과정을 거친다고 보면된다. 부스팅은 보통 두가지 방향이 있다.\n",
    "\n",
    "- 정답지와 오답지간의 차이를 훈련에 다시 투입하여 gradient를 적극 이용해서 모델을 개선하는 방식. XGboost나 lightGBM이 여기에 속한다.\n",
    "\n",
    "- GBM이란? : Gradient Boosting Machine(GBM)은 틀린부분에 가중치를 더하면서 진행하는 알고리즘\n",
    "\n",
    "- LGBM은 머신러닝 부스팅 알고리즘의 성능을 높인것이라고 할 수 있다.\n",
    "\n",
    "- 검증셋을 활용해서 검증셋에 대한 결과가 좋아지지 않을때까지 의사결정트리를 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-3.1.0-py2.py3-none-win_amd64.whl (751 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.19.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0) # 어느 컴퓨터에서 추출해도 똑같은 값이 나오도록 고정\n",
    "idx = random.sample(range(5121), 50) # 5000개의 컬럼중에 랜덤하게 50개를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold \n",
    "# 클래스 개수가 불균등하게 분포가 되어있기 때문에 train이랑 validation을 나눌때 균등하게 나누기 위해 StratifiedKFold를 사용\n",
    "skf = StratifiedKFold(n_splits=5) # n_splits=5 : 8대2로 나눔\n",
    "\n",
    "for trn_idx, val_idx in skf.split(X_train, y_train):\n",
    "    \n",
    "    X_trn, X_val, y_trn, y_val = X_train.iloc[trn_idx], X_train.iloc[val_idx], y_train.iloc[trn_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    break # break -> for문을 다 돌리지 않고 1번만 돌림."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMClassifier(n_estimators=50, learning_rate=0.03) \n",
    "# 분류문제이므로LGBMClassifier를 가져온다.\n",
    "# learning_rate, n_estimators 등 이런것들이 사용자가 직접 설정해야하는 옵션인 '하이퍼파라미터' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.938925981521606"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model_lgb.fit(X_trn.iloc[:,idx], y_trn)# 여기서는 validaion셋을 넣지 않아서 n_estimators=50을 모두 학습한다. -> 안좋음. #fit, predict함수는 그대로 scikit-learn처럼 사용, #idx -> 위에서 랜덤하게 뽑은 50개의 칼럼만 가지고\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- early stopping\n",
    "- 너무 적게 학습하면 즉 의사결정트리 수 n_estimators를 조금 주면 학습이 덜 됨 : 과소적합\n",
    "- 너무 많이 학습하면 noise까지 학습해버리기 때문에 더 이상한 모델이 나옴. 새로 들어오는 test데이터에 잘 맞아야 하는데 train 데이터에만 너무 학습되어서 망함 : 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaCApO9lKwhR"
   },
   "source": [
    "- **과소적합과 과대적합**\n",
    "\n",
    "![](https://datascience.foundation/img/pdf_images/underfitting_and_overfitting_in_machine_learning_some_degrees_and_train_our_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE94Y08WLwJh"
   },
   "source": [
    "- **검증 셋 활용**\n",
    "\n",
    "![](https://datavedas.com/wp-content/uploads/2018/04/image003.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84GyRV_VMIFr"
   },
   "source": [
    "- **Training Error vs Validation Error**\n",
    "\n",
    "  - 주황색 선이 validation error라고 봐주시길 바랍니다.\n",
    "\n",
    "![](https://www.textbook.ds100.org/_images/bias_cv_train_test_error.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred = model_lgb.predict_proba(X_val.iloc[:,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.03, objective='multiclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx) \n",
    "#-> 학습 시간 줄이려고(너무 오래걸리므로 just for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 4.26184\n",
      "[20]\tvalid_0's multi_logloss: 4.14101\n",
      "[30]\tvalid_0's multi_logloss: 4.08661\n",
      "[40]\tvalid_0's multi_logloss: 4.0672\n",
      "[50]\tvalid_0's multi_logloss: 4.07214\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's multi_logloss: 4.06639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.25992274284363"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model_lgb.fit(X_trn.iloc[:,idx], y_trn, \n",
    "              eval_set=(X_val.iloc[:,idx], y_val), \n",
    "              verbose = 10, #verbose = 10 : 10번 반복할 때마다 logloss값을 보여준다.\n",
    "              early_stopping_rounds=10) # early_stopping_rounds은 범위를 잡는 것, early_stopping_rounds를 조정해서 validation error가 최소가 되는 지점에 학습을 멈추도록\n",
    "time.time() - start \n",
    "# validation 셋을 활용해서 원하는 지점까지 학습 함.\n",
    "# n_estimators=100으로 설정해서 10, 20, 30.. 가다가 40~50사이에 loss값이 증가해서 42지점에서 알아서 멈춤. \n",
    "# 즉 validaion의 loss값이 최소가 될때 stop\n",
    "# 이런식으로 하이퍼파라미터를 조정할 수도 있음."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
