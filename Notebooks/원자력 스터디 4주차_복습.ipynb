{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 최적화: Grid Search & Random Search\n",
    "\n",
    "- Grid Search는 최적지점을 놓칠 확률이 random search에 비해 상대적으로 높다, 사용자가 parameter를 지정해줌. 탐색시간은 상대적으로 조금 걸린다.\n",
    "\n",
    "- Random Search는 사용자가 범위를 설정해주고 샘플링 수를 정해주면 알고리즘이 알아서 랜덤하게 cross validation을 해서 최적점을 찾을려고 한다 그래서 최적점을 찾을 확률이 상대적으로 높다. 샘플링 수를 높이면 학습하는 시간은 더 오래 걸리지만 최적점을 찾는 확률은 더 높아짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125.44715166091919\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train = pd.read_csv('../train.csv', index_col = 0)\n",
    "test = pd.read_csv('../test.csv', index_col = 0)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1200/1*ZTlQm_WRcrNqL-nLnx6GJA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,:5]\n",
    "y = train['label']\n",
    "#시간이 오래 걸려서 데이터를 추출해서 진행."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.03, max_depth=-1,\n",
       "                                      min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=100,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=0, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=True,\n",
       "                                      subsample=1.0, subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_estimators': [50], 'num_leaves': [10, 15]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV # GridSearchCV에서 CV는 CROSS VALIDATION, 성능평가를 같이 하기위해\n",
    "param = {'num_leaves': [10, 15], # 총 2개의 조합으로 하이퍼파라미터를 설정 (50, 10), (50, 15)\n",
    "        'n_estimators': [50]} # gridsearch\n",
    "\n",
    "model = lgb.LGBMClassifier(random_state = 0, learning_rate=0.03)\n",
    "\n",
    "gs = GridSearchCV(estimator=model, param_grid=param, scoring = 'neg_log_loss', cv = 3) # cv = 3 : kfold는 3으로 가져옴. 3개의 분할로 나누겠다. 2개는 학습으로 1개는 val로 한것을 총 3개\n",
    "\n",
    "# GridSearchCV개발자가 모델이 높은 점수를 가질수록 좋은 지표라고 설정을 해둠 따라서\n",
    "# 로그로스는 낮을수록 좋은 지표이기 때문에 뒤집어야한다. 따라서 negative를 설정\n",
    "\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'num_leaves': 10}\n",
      "{'mean_fit_time': array([5.62044366, 9.72578049]),\n",
      " 'mean_score_time': array([2.6352133 , 3.34682218]),\n",
      " 'mean_test_score': array([-4.34061464, -4.37139598]),\n",
      " 'param_n_estimators': masked_array(data=[50, 50],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_num_leaves': masked_array(data=[10, 15],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'n_estimators': 50, 'num_leaves': 10},\n",
      "            {'n_estimators': 50, 'num_leaves': 15}],\n",
      " 'rank_test_score': array([1, 2]),\n",
      " 'split0_test_score': array([-4.333528  , -4.36132573]),\n",
      " 'split1_test_score': array([-4.34583619, -4.37842419]),\n",
      " 'split2_test_score': array([-4.34247974, -4.37443802]),\n",
      " 'std_fit_time': array([0.19897029, 0.87574399]),\n",
      " 'std_score_time': array([0.37787969, 0.12742558]),\n",
      " 'std_test_score': array([0.00519499, 0.00730433])}\n"
     ]
    }
   ],
   "source": [
    "import pprint # pretty print의 약자, 이쁘게 보여주기 위해\n",
    "pprint.pprint(gs.best_params_) # best_params_ 이 속성에 최고의 조합이 들어감.\n",
    "\n",
    "pprint.pprint(gs.cv_results_) # cv_results_ 이 속성에는 gs를 돌렸을 때 나온 결과값이 저장.\n",
    "#mean_test_score가 평가 점수.\n",
    "#rank_test_score가 랭킹\n",
    "#split0_test_score...가 3번의 kfold 점수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict_proba(test.iloc[:, :5]) \n",
    "# gs가 위에서 나온 최고의 하이퍼파라미터들을 가지고 자동적으로 다시 학습함.(GridSearchCV의 안에 알고리즘이 있어서) 따라서 predict만 진행하면 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=LGBMClassifier(boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.03, max_depth=-1,\n",
       "                                            min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_leaves=31, objective=None,\n",
       "                                            random_state=0, reg_alpha=0.0,\n",
       "                                            reg_lambda=0.0, silent=True,\n",
       "                                            subsample=1.0,\n",
       "                                            subsample_for_bin=200000,\n",
       "                                            subsample_freq=0),\n",
       "                   iid='deprecated', n_iter=2, n_jobs=-1,\n",
       "                   param_distributions={'n_estimators': range(100, 200),\n",
       "                                        'num_leaves': range(10, 15)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "param = {'num_leaves': range(10, 15), # 범위를 설정해준다.\n",
    "        'n_estimators': range(100, 200)}\n",
    "\n",
    "model = lgb.LGBMClassifier(random_state = 0, learning_rate=0.03)\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=model,  # 튜닝하고자 하는 모델\n",
    "                        param_distributions=param, \n",
    "                        n_iter = 2, # 내가 몇번 샘플링을 반복할 것인지, 2개의 조합만 샘플링 하겠다.\n",
    "                        random_state=0, \n",
    "                        scoring = 'neg_log_loss', \n",
    "                        n_jobs = -1, cv = 3) \n",
    "\n",
    "rs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 109, 'num_leaves': 12}\n",
      "{'mean_fit_time': array([60.57826002, 48.56829977]),\n",
      " 'mean_score_time': array([83.7765859 , 71.58044314]),\n",
      " 'mean_test_score': array([-4.49011554, -4.44166262]),\n",
      " 'param_n_estimators': masked_array(data=[134, 109],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_num_leaves': masked_array(data=[12, 12],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'n_estimators': 134, 'num_leaves': 12},\n",
      "            {'n_estimators': 109, 'num_leaves': 12}],\n",
      " 'rank_test_score': array([2, 1]),\n",
      " 'split0_test_score': array([-4.48527946, -4.43597508]),\n",
      " 'split1_test_score': array([-4.49465466, -4.44535484]),\n",
      " 'split2_test_score': array([-4.4904125 , -4.44365794]),\n",
      " 'std_fit_time': array([0.82462336, 1.94688146]),\n",
      " 'std_score_time': array([0.11454041, 0.2121693 ]),\n",
      " 'std_test_score': array([0.00383316, 0.00408093])}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(rs.best_params_) # 가장 좋았던 조합\n",
    "\n",
    "pprint.pprint(rs.cv_results_) # 결과표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rs = rs.predict(test.iloc[:, :5]) # 이 친구도 가장 좋았던 하이퍼파라미터로 자동적으로 다시 학습하기 때문에 예측만 해주면 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 앙상블\n",
    "여러 모델을 합쳐서 예측을 하면 새로 들어오는 값에 대해 일반화가 잘될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  배깅\n",
    "soft or hard voting 같은거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators =10, n_jobs = -1, random_state = 0)\n",
    "clf2 = lgb.LGBMClassifier(n_estimators=10, random_state = 0, learning_rate=0.03)\n",
    "#초기모델선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = VotingClassifier(estimators=[('rf', clf1), ('lgbm', clf2)], \n",
    "                         voting='soft') # soft voting으로 설정해서 위의 두개의 모델을 합친다.\n",
    "\n",
    "eclf1 = eclf1.fit(X, y) #학습할 때는 fit함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rf',\n",
       "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                         oob_score=False, random_state=0, verbose=0,\n",
       "                         warm_start=False)),\n",
       " ('lgbm',\n",
       "  LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                 importance_type='split', learning_rate=0.03, max_depth=-1,\n",
       "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                 n_estimators=10, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                 random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf1.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_vote = eclf1.predict_proba(test.iloc[:, :5]) # 예측값의 평균으로 마지막에 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00113591, 0.00109712, 0.00113622, ..., 0.00055586, 0.00053781,\n",
       "        0.000507  ],\n",
       "       [0.0011484 , 0.0010874 , 0.00112431, ..., 0.00050887, 0.00100015,\n",
       "        0.00051258],\n",
       "       [0.00109916, 0.00099029, 0.00136401, ..., 0.00046762, 0.00053066,\n",
       "        0.00050647],\n",
       "       ...,\n",
       "       [0.00095534, 0.00094977, 0.00092074, ..., 0.00044184, 0.00053738,\n",
       "        0.00046011],\n",
       "       [0.05109638, 0.00106991, 0.00111967, ..., 0.00046408, 0.00052065,\n",
       "        0.00055006],\n",
       "       [0.00109108, 0.00326838, 0.00103893, ..., 0.00053392, 0.00050373,\n",
       "        0.00049263]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스태킹\n",
    "평균 내기보다 확률 값별로의 가중치를 다르게 가져가서 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators =10, n_jobs = -1, random_state = 0)\n",
    "clf2 = lgb.LGBMClassifier(n_estimators=10, random_state = 0, learning_rate=0.03)\n",
    "# 모델선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(estimators=[('rf', clf1), ('lgbm', clf2)], #모델 합치기\n",
    "    final_estimator=LogisticRegression(),\n",
    "                        n_jobs = -1, \n",
    "                        stack_method = 'predict_proba',\n",
    "                        cv = 3)\n",
    "# rf랑 lgb로부터 나온 예측값에 가중치를 주어서 새로운 파이널 모델에 넣고 재학습. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack = clf.predict_proba(test.iloc[:, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00216586, 0.00210159, 0.0021522 , ..., 0.00127722, 0.00137432,\n",
       "        0.00135569],\n",
       "       [0.0020739 , 0.00215997, 0.00196321, ..., 0.00153504, 0.00146594,\n",
       "        0.00151122],\n",
       "       [0.00196064, 0.00182352, 0.00195937, ..., 0.00117609, 0.00134152,\n",
       "        0.00121692],\n",
       "       ...,\n",
       "       [0.00213839, 0.00195489, 0.00243081, ..., 0.00135868, 0.00124919,\n",
       "        0.00139169],\n",
       "       [0.00215344, 0.00206992, 0.00241268, ..., 0.00138046, 0.00138189,\n",
       "        0.00143969],\n",
       "       [0.00223416, 0.00217609, 0.00205226, ..., 0.00136906, 0.00130006,\n",
       "        0.00142649]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_stack"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
